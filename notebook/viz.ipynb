{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install dash\n",
    "pip install dash-bootstrap-components\n",
    "pip install dash-mantine-components==0.12.1\n",
    "pip install dash-holoniq-wordcloud\n",
    "\n",
    "**SATISFACTION CLIENT SENTIMENT ANALYSIS AND DASHBOARD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Importation des librairies\n",
    "import dash\n",
    "from dash import Dash, html, dcc, Output, Input\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import dash_bootstrap_components as dbc\n",
    "import requests  # Nouveau\n",
    "import warnings\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Base URL de l'API Flask\n",
    "#BASE_URL = \"http://flask_api:5000/api\"\n",
    "BASE_URL = \"http://localhost:5000/api\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les données des entreprises via l'API\n",
    "companies_response = requests.get(f\"{BASE_URL}/companies\")\n",
    "if companies_response.status_code == 200:\n",
    "    df = pd.DataFrame(companies_response.json())\n",
    "else:\n",
    "    print(\"Erreur lors de la récupération des entreprises :\", companies_response.json())\n",
    "    df = pd.DataFrame()  # DataFrame vide en cas d'erreur\n",
    "\n",
    "# Récupérer les données des commentaires via l'API\n",
    "comments_response = requests.get(f\"{BASE_URL}/comments\")\n",
    "if comments_response.status_code == 200:\n",
    "    df_comments = pd.DataFrame(comments_response.json())\n",
    "else:\n",
    "    print(\"Erreur lors de la récupération des commentaires :\", comments_response.json())\n",
    "    df_comments = pd.DataFrame()  # DataFrame vide en cas d'erreur\n",
    "\n",
    "# Renommer la colonne 'five_star_percentage' en 'five_star_%'\n",
    "df.rename(columns={'five_star_percentage': 'five_star_%'}, inplace=True)\n",
    "\n",
    "#Renommer la colonne review\n",
    "df.rename(columns={'review': 'nombre_reviews'}, inplace=True)\n",
    "\n",
    "# Concaténer '%' aux valeurs et ignorer les NaN\n",
    "df['five_star_%'] = df['five_star_%'].apply(lambda x: f\"{x :.0f}%\" if pd.notna(x) and isinstance(x, (int, float)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>User</th>\n",
       "      <th>commentaire</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date_experience</th>\n",
       "      <th>localisation</th>\n",
       "      <th>nombre_reviews</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank and staff great, ATM locations are terria...</td>\n",
       "      <td>coRpSE</td>\n",
       "      <td>I have had great experience with them, but, I ...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>October 15, 2024</td>\n",
       "      <td>US</td>\n",
       "      <td>1 review</td>\n",
       "      <td>{'reply_date': 'Monday, October 21, 2024 at 04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great customer service</td>\n",
       "      <td>Tony Field</td>\n",
       "      <td>Casey was a pleasure to deal with, quick respo...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>November 05, 2024</td>\n",
       "      <td>US</td>\n",
       "      <td>1 review</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Casey was amazing with the used auto…</td>\n",
       "      <td>Brian Conroy</td>\n",
       "      <td>Casey was amazing with the used auto loan &amp; en...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>September 25, 2024</td>\n",
       "      <td>US</td>\n",
       "      <td>1 review</td>\n",
       "      <td>{'reply_date': 'Monday, October 7, 2024 at 04:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evergreen Credit Union was amazing to…</td>\n",
       "      <td>Sherry Spaulding</td>\n",
       "      <td>Evergreen Credit Union was amazing to work wit...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>July 02, 2024</td>\n",
       "      <td>US</td>\n",
       "      <td>1 review</td>\n",
       "      <td>{'reply_date': 'Monday, July 8, 2024 at 08:41:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing Team at Evergreen</td>\n",
       "      <td>Ashleigh Scalamandre</td>\n",
       "      <td>I just wanted to thank the Evergreen Team agai...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>July 09, 2024</td>\n",
       "      <td>US</td>\n",
       "      <td>1 review</td>\n",
       "      <td>{'reply_date': 'Thursday, July 18, 2024 at 05:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Best Ever Banking Experience</td>\n",
       "      <td>Lindsay Edwards</td>\n",
       "      <td>Casey has been amazing to work with. I have be...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>May 23, 2024</td>\n",
       "      <td>US</td>\n",
       "      <td>1 review</td>\n",
       "      <td>{'reply_date': 'Tuesday, May 28, 2024 at 08:03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Security</td>\n",
       "      <td>Ken</td>\n",
       "      <td>I called the Evergreen's Portland location on ...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>April 20, 2024</td>\n",
       "      <td>SE</td>\n",
       "      <td>1 review</td>\n",
       "      <td>{'reply_date': 'Monday, May 6, 2024 at 07:35:4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I requested bank statements and the…</td>\n",
       "      <td>Noel Sherburne</td>\n",
       "      <td>I requested bank statements and the request wa...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>June 18, 2024</td>\n",
       "      <td>US</td>\n",
       "      <td>1 review</td>\n",
       "      <td>{'reply_date': 'Thursday, June 20, 2024 at 04:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rebecca was very helpful in finding my…</td>\n",
       "      <td>Charlie Quatrano</td>\n",
       "      <td>Rebecca was very helpful in finding my transac...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>August 02, 2024</td>\n",
       "      <td>US</td>\n",
       "      <td>1 review</td>\n",
       "      <td>{'reply_date': 'Monday, August 26, 2024 at 03:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Disappointed</td>\n",
       "      <td>Marian Giovannini</td>\n",
       "      <td>I was very disappointed to be denied a credit ...</td>\n",
       "      <td>Evergreen Credit Union</td>\n",
       "      <td>July 18, 2024</td>\n",
       "      <td>US</td>\n",
       "      <td>1 review</td>\n",
       "      <td>{'reply_date': 'Thursday, July 18, 2024 at 05:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Titre                  User  \\\n",
       "0  bank and staff great, ATM locations are terria...                coRpSE   \n",
       "1                             Great customer service            Tony Field   \n",
       "2              Casey was amazing with the used auto…          Brian Conroy   \n",
       "3             Evergreen Credit Union was amazing to…      Sherry Spaulding   \n",
       "4                          Amazing Team at Evergreen  Ashleigh Scalamandre   \n",
       "5                       Best Ever Banking Experience       Lindsay Edwards   \n",
       "6                                           Security                   Ken   \n",
       "7               I requested bank statements and the…        Noel Sherburne   \n",
       "8            Rebecca was very helpful in finding my…      Charlie Quatrano   \n",
       "9                                       Disappointed     Marian Giovannini   \n",
       "\n",
       "                                         commentaire            company_name  \\\n",
       "0  I have had great experience with them, but, I ...  Evergreen Credit Union   \n",
       "1  Casey was a pleasure to deal with, quick respo...  Evergreen Credit Union   \n",
       "2  Casey was amazing with the used auto loan & en...  Evergreen Credit Union   \n",
       "3  Evergreen Credit Union was amazing to work wit...  Evergreen Credit Union   \n",
       "4  I just wanted to thank the Evergreen Team agai...  Evergreen Credit Union   \n",
       "5  Casey has been amazing to work with. I have be...  Evergreen Credit Union   \n",
       "6  I called the Evergreen's Portland location on ...  Evergreen Credit Union   \n",
       "7  I requested bank statements and the request wa...  Evergreen Credit Union   \n",
       "8  Rebecca was very helpful in finding my transac...  Evergreen Credit Union   \n",
       "9  I was very disappointed to be denied a credit ...  Evergreen Credit Union   \n",
       "\n",
       "      date_experience localisation nombre_reviews  \\\n",
       "0    October 15, 2024           US       1 review   \n",
       "1   November 05, 2024           US       1 review   \n",
       "2  September 25, 2024           US       1 review   \n",
       "3       July 02, 2024           US       1 review   \n",
       "4       July 09, 2024           US       1 review   \n",
       "5        May 23, 2024           US       1 review   \n",
       "6      April 20, 2024           SE       1 review   \n",
       "7       June 18, 2024           US       1 review   \n",
       "8     August 02, 2024           US       1 review   \n",
       "9       July 18, 2024           US       1 review   \n",
       "\n",
       "                                               reply  \n",
       "0  {'reply_date': 'Monday, October 21, 2024 at 04...  \n",
       "1                                               None  \n",
       "2  {'reply_date': 'Monday, October 7, 2024 at 04:...  \n",
       "3  {'reply_date': 'Monday, July 8, 2024 at 08:41:...  \n",
       "4  {'reply_date': 'Thursday, July 18, 2024 at 05:...  \n",
       "5  {'reply_date': 'Tuesday, May 28, 2024 at 08:03...  \n",
       "6  {'reply_date': 'Monday, May 6, 2024 at 07:35:4...  \n",
       "7  {'reply_date': 'Thursday, June 20, 2024 at 04:...  \n",
       "8  {'reply_date': 'Monday, August 26, 2024 at 03:...  \n",
       "9  {'reply_date': 'Thursday, July 18, 2024 at 05:...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>country</th>\n",
       "      <th>five_star_%</th>\n",
       "      <th>institution_type</th>\n",
       "      <th>nombre_reviews</th>\n",
       "      <th>town</th>\n",
       "      <th>trust_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>95%</td>\n",
       "      <td>Financial Institution</td>\n",
       "      <td>346</td>\n",
       "      <td>Portland</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>92%</td>\n",
       "      <td>Financial Institution</td>\n",
       "      <td>320</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>66%</td>\n",
       "      <td>Bank</td>\n",
       "      <td>3322</td>\n",
       "      <td>Irvine</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>65%</td>\n",
       "      <td>Cryptocurrency Service</td>\n",
       "      <td>227</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>100%</td>\n",
       "      <td>Software Vendor</td>\n",
       "      <td>15</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>93%</td>\n",
       "      <td>Financial Institution</td>\n",
       "      <td>15</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>100%</td>\n",
       "      <td>Financial Institution</td>\n",
       "      <td>10</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>100%</td>\n",
       "      <td>Business to Business Service</td>\n",
       "      <td>4</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>67%</td>\n",
       "      <td>Debt Relief Service</td>\n",
       "      <td>9</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>United States</td>\n",
       "      <td>37%</td>\n",
       "      <td>ATM</td>\n",
       "      <td>8</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id company_name         country five_star_%  \\\n",
       "0           1         None   United States         95%   \n",
       "1           2         None   United States         92%   \n",
       "2           3         None   United States         66%   \n",
       "3           4         None   United States         65%   \n",
       "4           5         None   United States        100%   \n",
       "5           6         None   United States         93%   \n",
       "6           7         None   United States        100%   \n",
       "7           8         None   United States        100%   \n",
       "8           9         None   United States         67%   \n",
       "9          10         None   United States         37%   \n",
       "\n",
       "               institution_type  nombre_reviews           town  trust_score  \n",
       "0         Financial Institution             346       Portland          4.8  \n",
       "1         Financial Institution             320        Lincoln          4.8  \n",
       "2                          Bank            3322         Irvine          4.3  \n",
       "3        Cryptocurrency Service             227        Chicago          4.1  \n",
       "4               Software Vendor              15      Cleveland          4.5  \n",
       "5         Financial Institution              15        Atlanta          4.4  \n",
       "6         Financial Institution              10  San Francisco          4.4  \n",
       "7  Business to Business Service               4     San Diego           4.0  \n",
       "8           Debt Relief Service               9       San Jose          3.8  \n",
       "9                           ATM               8      Las Vegas          3.7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REQUETES SUR COMPANIES ET REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LECTURE DES DONNEES COMPANIES ET REVIEWS SUR LA DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_comment_processing(df_comments):\n",
    "\n",
    "    df_comments['company_name']= df_comments['company_name'].apply(lambda x: str(x).strip()[:11] + \"...\")\n",
    "\n",
    "    text_df = df_comments.drop(['User', 'localisation', 'Titre','nombre_reviews', 'date_experience', 'reply'\n",
    "           ], axis=1)\n",
    "           \n",
    "    text_df.rename(columns={'commentaire': 'text'}, inplace=True)\n",
    "    #text_df.head()\n",
    "\n",
    "    return text_df\n",
    "\n",
    "#Comment processing\n",
    "def comments_preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https\\S+|www\\S+https\\S+\", '',text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@w+|\\#','',text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text_tokens = word_tokenize(text)\n",
    "    filtered_text = [w for w in text_tokens if not w in stop_words]\n",
    "\n",
    "    return \" \".join(filtered_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données de commentaires récupérées :                                                  Titre                  User  \\\n",
      "0    bank and staff great, ATM locations are terria...                coRpSE   \n",
      "1                               Great customer service            Tony Field   \n",
      "2                Casey was amazing with the used auto…          Brian Conroy   \n",
      "3               Evergreen Credit Union was amazing to…      Sherry Spaulding   \n",
      "4                            Amazing Team at Evergreen  Ashleigh Scalamandre   \n",
      "..                                                 ...                   ...   \n",
      "375                     Most ungrateful bank out there                  Kai.   \n",
      "376                                 PNC is so horrible        Christy Hedger   \n",
      "377                             I never in my lifetime                Johnny   \n",
      "378                                Great Start Up Bank                P MacG   \n",
      "379                 Had Fraudulent charges $1,100 PNC…       Todd lane Brown   \n",
      "\n",
      "                                           commentaire  \\\n",
      "0    I have had great experience with them, but, I ...   \n",
      "1    Casey was a pleasure to deal with, quick respo...   \n",
      "2    Casey was amazing with the used auto loan & en...   \n",
      "3    Evergreen Credit Union was amazing to work wit...   \n",
      "4    I just wanted to thank the Evergreen Team agai...   \n",
      "..                                                 ...   \n",
      "375  I want to say PNC has got to be the most ungra...   \n",
      "376  PNC is so horrible. If I could give negative s...   \n",
      "377  I never in my lifetime, had to deal with a ban...   \n",
      "378  Now although things may have ended abruptly, d...   \n",
      "379  Had Fraudulent charges $1,100 PNC refunded $33...   \n",
      "\n",
      "               company_name     date_experience localisation nombre_reviews  \\\n",
      "0    Evergreen Credit Union    October 15, 2024           US       1 review   \n",
      "1    Evergreen Credit Union   November 05, 2024           US       1 review   \n",
      "2    Evergreen Credit Union  September 25, 2024           US       1 review   \n",
      "3    Evergreen Credit Union       July 02, 2024           US       1 review   \n",
      "4    Evergreen Credit Union       July 09, 2024           US       1 review   \n",
      "..                      ...                 ...          ...            ...   \n",
      "375                PNC Bank    October 21, 2024           US     20 reviews   \n",
      "376                PNC Bank    October 15, 2024           US     20 reviews   \n",
      "377                PNC Bank   November 02, 2024           US     20 reviews   \n",
      "378                PNC Bank    October 06, 2023           US     20 reviews   \n",
      "379                PNC Bank  September 20, 2024           US     20 reviews   \n",
      "\n",
      "                                                 reply  \n",
      "0    {'reply_date': 'Monday, October 21, 2024 at 04...  \n",
      "1                                                 None  \n",
      "2    {'reply_date': 'Monday, October 7, 2024 at 04:...  \n",
      "3    {'reply_date': 'Monday, July 8, 2024 at 08:41:...  \n",
      "4    {'reply_date': 'Thursday, July 18, 2024 at 05:...  \n",
      "..                                                 ...  \n",
      "375                                               None  \n",
      "376                                               None  \n",
      "377                                               None  \n",
      "378                                               None  \n",
      "379                                               None  \n",
      "\n",
      "[380 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Stream word\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stemming(data):\n",
    "    text = [stemmer.stem(word) for word in data]\n",
    "    return data\n",
    "\n",
    "#Polarity fxn\n",
    "def polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "#Comment status\n",
    "def sentiment(label):\n",
    "    if label <0:\n",
    "        return \"Negative\"\n",
    "    elif label ==0:\n",
    "        return \"Neutral\"\n",
    "    elif label>0:\n",
    "        return \"Positive\"\n",
    "\n",
    "\n",
    "def comment_polarity(text_df):\n",
    "    \n",
    "    #text_df.text = text_df['text'].apply(comments_preprocessing)\n",
    "    text_df = text_df.drop_duplicates('text')\n",
    "\n",
    "    #apply streamer\n",
    "    text_df['text'] = text_df['text'].apply(lambda x: stemming(x))\n",
    "\n",
    "    #compute polarity\n",
    "    text_df['polarity'] = text_df['text'].apply(polarity)\n",
    "\n",
    "    #Detect comment polarity\n",
    "    text_df['sentiment'] = text_df['polarity'].apply(sentiment)\n",
    "\n",
    "    return text_df\n",
    "\n",
    "# Vérifiez les données récupérées par l'API\n",
    "print(\"Données de commentaires récupérées :\", df_comments)\n",
    "\n",
    "\n",
    "def compute_sentiment_analysis(df_comments):\n",
    "\n",
    "    text_df = company_comment_processing(df_comments)\n",
    "\n",
    "    df_polarity =pd.DataFrame()\n",
    "\n",
    "    for company in text_df.company_name.unique():\n",
    "        text_df[text_df.company_name==company]\n",
    "        comp_pol =comment_polarity(text_df[text_df.company_name==company])\n",
    "        comp_pol['company_name']= company\n",
    "        df_polarity= pd.concat([df_polarity,comp_pol])\n",
    "\n",
    "    #fig = plt.figure(figsize=(5,5))\n",
    "    #sns.countplot(x='sentiment', data = df_polarity)\n",
    "    return df_polarity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_company_sentiment_count_per_year(df_comments, df_polarity):\n",
    "\n",
    "    df_comments.rename(columns={\"commentaire\": \"text\"}, inplace=True)\n",
    "    df_p = df_polarity.merge(df_comments[['year', 'company_name','text']], on=['text', 'company_name'], how='left')\n",
    "    \n",
    "    # Group by company_name, year, and sentiment, then count the occurrences\n",
    "    grouped_df = df_p.groupby(['company_name', 'year', 'sentiment']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Reset the index to make the DataFrame more readable\n",
    "    grouped_df = grouped_df.reset_index()\n",
    "\n",
    "    #print(grouped_df.head())\n",
    "\n",
    "    return grouped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grouped_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgrouped_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grouped_df' is not defined"
     ]
    }
   ],
   "source": [
    "grouped_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grouped_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_g \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      3\u001b[0m df_g\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grouped_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_g = grouped_df.groupby(['year', 'company_name']).size().reset_index()\n",
    "\n",
    "df_g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m comments_over_time_fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mline(df_g, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_comments\u001b[39m\u001b[38;5;124m'\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of Comments Over Time\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m'\u001b[39m, markers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Sentiment Analysis Histogram per year per company\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_company_sentiment_count_per_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_comments\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_polarity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m################################################################################################################\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m###### Dashboards/layouts \u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m################################################################################################################\u001b[39;00m\n\u001b[0;32m     70\u001b[0m app\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m=\u001b[39m dbc\u001b[38;5;241m.\u001b[39mContainer([\n\u001b[0;32m     71\u001b[0m     dbc\u001b[38;5;241m.\u001b[39mRow([        \n\u001b[0;32m     72\u001b[0m         \u001b[38;5;66;03m############### Add filters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m     ]),\n\u001b[0;32m    112\u001b[0m ])\n",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m, in \u001b[0;36mget_company_sentiment_count_per_year\u001b[1;34m(df_comments, df_polarity)\u001b[0m\n\u001b[0;32m      4\u001b[0m df_p \u001b[38;5;241m=\u001b[39m df_polarity\u001b[38;5;241m.\u001b[39mmerge(df_comments[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Group by company_name, year, and sentiment, then count the occurrences\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompany_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39munstack(fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Reset the index to make the DataFrame more readable\u001b[39;00m\n\u001b[0;32m     10\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m grouped_df\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\MSI KATANA B13V\\Desktop\\PARCOURS DE\\Projet Fil Rouge\\de_satisfaction_client\\_myenv\\lib\\site-packages\\pandas\\core\\frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   8399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   8400\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8405\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8408\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8410\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MSI KATANA B13V\\Desktop\\PARCOURS DE\\Projet Fil Rouge\\de_satisfaction_client\\_myenv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\MSI KATANA B13V\\Desktop\\PARCOURS DE\\Projet Fil Rouge\\de_satisfaction_client\\_myenv\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    886\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    891\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'year'"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load data\n",
    "#df = pd.read_csv('atm_company_info.csv')\n",
    "\n",
    "# Initialize Dash app\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "###### Company Analysis Figures\n",
    "################################################################################################################\n",
    "# Map Visualization\n",
    "#map_fig = px.scatter_mapbox(df, lat='latitude', lon='longitude', hover_name='company_name',\n",
    "#                            color='trust_score', size='trust_score',\n",
    "#                            mapbox_style=\"carto-positron\", zoom=3, height=500)\n",
    "\n",
    "# Company Trust Score Bar Chart\n",
    "trust_fig = px.bar(df, y='company_name', x='trust_score', color='trust_score', title=\"Trust Score by Company\")\n",
    "trust_fig.update_layout(barmode='stack', yaxis={'categoryorder':'total ascending'}, height=500)\n",
    "\n",
    "# Institution Type Pie Chart\n",
    "institution_fig = px.pie(df, names='institution_type', title=\"Institution Type Distribution\")\n",
    "\n",
    "# Review Distribution Histogram\n",
    "# Remove the '%' sign and convert to numeric type\n",
    "df['five_star_%'] = df['five_star_%'].str.rstrip('%').astype('float')\n",
    "df = df.sort_values('five_star_%')\n",
    "df['five_star_%'] = df['five_star_%'].astype(str) + '%'\n",
    "review_dist_fig = px.histogram(df, x='five_star_%', title=\"Review Distribution\", color='five_star_%')\n",
    "\n",
    "# Top Reviewed Companies\n",
    "top_companies_fig = px.bar(df.sort_values(by='nombre_reviews', ascending=False).head(10), \n",
    "                           x='company_name', y='nombre_reviews', title=\"Top Reviewed Companies\")\n",
    "\n",
    "# Company Comparison Radar Chart (trust_score vs five_star_%)\n",
    "#df_melt = pd.melt(df, id_vars=['company_name'], value_vars=['trust_score', 'five_star_%'])\n",
    "#comparison_fig = px.line_polar(df_melt, r='value', theta='variable', color='company_name', \n",
    "#                               line_close=True, title=\"Company Comparison\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "###### Comment Sentiment Analysis \n",
    "################################################################################################################\n",
    "#print(\" Comment Sentiment Analysis\")\n",
    "\n",
    "\n",
    "# Example sentiment analysis - dummy data\n",
    "#df_comments['sentiment'] = df_comments['commentaire'].apply(lambda x: 'Positive' if 'good' in x else 'Negative')\n",
    "\n",
    "df_polarity = compute_sentiment_analysis(df_comments)\n",
    "# Sentiment Analysis Bar Chart\n",
    "sentiment_fig = px.bar(df_polarity, x='company_name', color='sentiment', title=\"Sentiment Analysis per company\")\n",
    "\n",
    "# Comments Over Time Line Chart\n",
    "df_comments['date_experience'] = pd.to_datetime(df_comments['date_experience'])\n",
    "df_comments['year'] = df_comments.date_experience.dt.year\n",
    "df_g = df_comments.groupby(['year', 'company_name']).size().reset_index()\n",
    "df_g.rename(columns={0: 'nbr_comments'}, inplace=True)\n",
    "comments_over_time_fig = px.line(df_g, x='year', y='nbr_comments', title=\"Number of Comments Over Time\", color='company_name', markers=True)\n",
    "\n",
    "# Sentiment Analysis Histogram per year per company\n",
    "grouped_df = get_company_sentiment_count_per_year(df_comments,df_polarity)\n",
    "\n",
    "################################################################################################################\n",
    "###### Dashboards/layouts \n",
    "################################################################################################################\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row([        \n",
    "        ############### Add filters\n",
    "        dbc.Col([dcc.Graph(figure=map_fig)], width=12),\n",
    "        dbc.Col([html.H4(\"Company Dashboard\")], width=12),\n",
    "        #dbc.Col([dcc.Dropdown(\n",
    "        #    id='dropdown-town',\n",
    "        #    options=[{'label': x, 'value': x} for x in df['town'].unique()],\n",
    "        #    multi=True,\n",
    "        #    placeholder=\"Select a town\"\n",
    "        #)], width=6),\n",
    "        #dbc.Col([ dcc.Dropdown(\n",
    "        #    id='filter-country',\n",
    "        #    options=[{'label': x, 'value': x} for x in df['country'].unique()],\n",
    "        #    multi=False,\n",
    "        #    placeholder=\"Select a Country\"\n",
    "        #)], width=6),     \n",
    "        dbc.Col([dcc.Graph( id = 'filter-town',figure=trust_fig)], width=6),\n",
    "        #dbc.Col([dcc.Graph(figure=institution_fig)], width=6),\n",
    "        dbc.Col([dcc.Graph(figure=top_companies_fig)], width=6),\n",
    "        #dbc.Col([dcc.Graph(figure=review_dist_fig)], width=6),\n",
    "        #dbc.Col([dcc.Graph(figure=comparison_fig)], width=6),\n",
    "        #dbc.Col([dcc.Graph(id='filtered-graph')], width=6),\n",
    "    ]),\n",
    "    dbc.Row([        \n",
    "        dbc.Col([html.H4(\"User Feedback Dashboard\")], width=12),\n",
    "        dbc.Col([dcc.Graph(figure=sentiment_fig)], width=6),\n",
    "        dbc.Col([dcc.Graph(figure=comments_over_time_fig)], width=6), \n",
    "\n",
    "        html.H1(\"Sentiment Analysis Histogram per year per company\"),\n",
    "        # Dropdown for selecting a company\n",
    "        dcc.Dropdown(\n",
    "            id='company-dropdown',\n",
    "            options=[{'label': company, 'value': company} for company in grouped_df['company_name'].unique()],\n",
    "            value=grouped_df['company_name'].unique()[0],  # Default to the first company\n",
    "            clearable=False,\n",
    "            style={'width': '50%'}\n",
    "        ),\n",
    "    \n",
    "    # Graph to display the histogram\n",
    "    dcc.Graph(id='histogram'),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "# Filtered Trust Score Chart\n",
    "\"\"\"@app.callback(\n",
    "    dash.dependencies.Output('filtered-graph', 'figure'),\n",
    "    [dash.dependencies.Input('dropdown-town', 'value')]\n",
    ")\"\"\"\n",
    "\n",
    "def update_graph(selected_town):\n",
    "    if selected_town:\n",
    "        filtered_df = df[df['town'].isin(selected_town)]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "    \n",
    "    fig = px.bar(filtered_df, x='company_name', y='trust_score', color='trust_score', title=\"Filtered Trust Score\")\n",
    "    fig.update_layout(xaxis_title=\"Year\", yaxis_title=\"Count\")\n",
    "    return fig\n",
    "\n",
    "# Define the callback to update the graph based on the selected company\n",
    "@app.callback(\n",
    "    Output('histogram', 'figure'),\n",
    "    [Input('company-dropdown', 'value')]\n",
    ")\n",
    "def update_histogram(selected_company):\n",
    "    # Filter the DataFrame for the selected company\n",
    "    filtered_df = grouped_df[grouped_df['company_name'] == selected_company]\n",
    "    \n",
    "    # Create a histogram using Plotly Express\n",
    "    fig = px.bar(\n",
    "        filtered_df.melt(id_vars=['company_name', 'year']),\n",
    "        x='year',\n",
    "        y='value',\n",
    "        color='sentiment',\n",
    "        barmode='group',\n",
    "        title=f'Sentiment Types Trend for {selected_company} per Year'\n",
    "    )\n",
    "    fig.update_layout(xaxis_title=\"Year\", yaxis_title=\"Count\")\n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(host='localhost', port=8050, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
